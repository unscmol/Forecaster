import os
import sys
import json
import numpy as np
import pandas as pd
import pickle
import shutil
import matplotlib.pyplot as plt
import joblib
import datetime

#å¼•å…¥è‡ªå®šä¹‰å‡½æ•°
sys.path.append(r"..\src\untils")
sys.path.append(r"..\src\model_evaluator")
from forecaster_fuction import check_missing_values, split_train_test_data_by_time

'''åœ¨æ­¤å¯¼å…¥ä½ éœ€è¦æµ‹è¯•çš„ç±»'''
from evaluate_src import Task_Evaluator
from post_process import Task_Processor

'''
æŒ‡å®šä»»åŠ¡æµ‹è¯•ç”¨çš„jsonå‚æ•°æ–‡ä»¶ä½ç½®ï¼Œèµ‹å€¼ç»™job_params_fileğŸ‘‡
'''
job_params_file = "è¯·å¡«å†™éœ€è¦debugçš„ä»»åŠ¡çš„è¶…å‚æ•°æ–‡ä»¶è·¯å¾„"

# è¯»å–è¶…å‚æ•°
with open(job_params_file, "r") as f:
    job_params = json.load(f)

# æå–ç”¨æˆ·å’Œä»»åŠ¡æ ‡è¯†
username = job_params["user_id"]
job_number = job_params["job_number"]

# æ„é€ æ—¥å¿—ç›®å½•å’Œæ–‡ä»¶å
log_dir = os.path.abspath(os.path.join("..", "misc", "log"))
os.makedirs(log_dir, exist_ok=True)

log_filename = f"task_evaluate_{username}_jobid{job_number}.log"
log_path = os.path.join(log_dir, log_filename)

# å°† stdout å’Œ stderr é‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶
sys.stdout = open(log_path, 'w', encoding='utf-8')
sys.stderr = sys.stdout  # é”™è¯¯ä¹Ÿå†™å…¥æ—¥å¿—

print(f"[{datetime.datetime.now()}] å¼€å§‹è¿è¡Œæµ‹è¯•ä»£ç  user_id={username}, job_id={job_number}")
print(f"ä½¿ç”¨å‚æ•°æ–‡ä»¶: {job_params_file}")


import traceback

try:
    '''åœ¨å¦‚ä¸‹è¿è¡Œä½ éœ€è¦æµ‹è¯•çš„ä»£ç ç„¶ååœ¨Forecaster\misc\logç›®å½•ä¸‹æŸ¥çœ‹debugçš„æ—¥å¿—'''
    Evaluate_Task = Task_Evaluator(
        job_params,
        job_params['user_id'],
        job_params['task_id'],
        job_params['job_number']
    )
    Evaluate_Task.execute_eva()
    print(f"[{datetime.datetime.now()}] æµ‹è¯•å®Œæˆ âœ…")

except Exception as e:
    print(f"[{datetime.datetime.now()}] æµ‹è¯•å¤±è´¥ âŒ: {str(e)}")
    print("è¯¦ç»†é”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼š")
    traceback.print_exc()  # æ‰“å°å®Œæ•´ traceback åˆ°æ—¥å¿—æ–‡ä»¶

finally:
    sys.stdout.flush()
    sys.stdout.close()