{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:20:55.084871Z",
     "start_time": "2025-04-28T08:20:55.071872Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# 定义函数\n",
    "def normalization(data_series):\n",
    "    scale = MinMaxScaler()\n",
    "    data_n = np.array(data_series).reshape(-1, 1)\n",
    "    data_n = scale.fit_transform(data_n)\n",
    "    data_n = pd.DataFrame(data_n, index=data_series.index)\n",
    "    return np.array(data_n).reshape(-1, 1), scale\n",
    "\n",
    "def create_data(data_n, inp_len, out_len, step_len):\n",
    "    inp_data, dec_inp, out_data = [], [], []\n",
    "    for i in range(0, data_n.shape[0] - inp_len - out_len, step_len): # 没有缺失值\n",
    "        if not np.isnan(data_n[i:i + inp_len]).any() and not np.isnan(data_n[i + inp_len:i + inp_len + out_len]).any():\n",
    "            inp_data.append(data_n[i:i + inp_len, 0])\n",
    "            # dec_inp.append(data_n[i:i + inp_len, 1])\n",
    "            out_data.append(data_n[i + inp_len:i + inp_len + out_len, 0])\n",
    "    inp_data, out_data = np.stack(inp_data), np.stack(out_data)\n",
    "    return inp_data.reshape(-1, out_len, 1), out_data.reshape(-1, out_len, 1)\n",
    "\n",
    "def acc_cal(true, pre):\n",
    "    # 确保输入的形状正确\n",
    "    if true.shape != pre.shape:\n",
    "        raise ValueError(\"The shape of true and pre must be the same.\")\n",
    "    rmse_per_sample = np.sqrt(np.mean((true - pre) ** 2, axis=1))\n",
    "    acc = (1 - np.mean(rmse_per_sample)) * 100\n",
    "    return acc\n",
    "\n",
    "\n",
    "def reverse_normalize(data, scaler_max, scaler_min):\n",
    "    return data * (scaler_max - scaler_min) + scaler_min\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0153  ver loss:0.0149\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0145  ver loss:0.0146\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0149  ver loss:0.0142\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0146  ver loss:0.0142\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0152  ver loss:0.0142\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0137  ver loss:0.0140\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0138  ver loss:0.0140\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0147  ver loss:0.0138\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0138  ver loss:0.0140\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0135  ver loss:0.0139\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0151  ver loss:0.0185\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0141  ver loss:0.0179\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0135  ver loss:0.0176\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0139  ver loss:0.0176\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0136  ver loss:0.0179\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0139  ver loss:0.0176\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0142  ver loss:0.0177\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0143  ver loss:0.0182\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0147  ver loss:0.0178\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0135  ver loss:0.0182\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0140  ver loss:0.0108\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0134  ver loss:0.0105\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0136  ver loss:0.0105\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0133  ver loss:0.0104\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0135  ver loss:0.0108\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0139  ver loss:0.0106\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0149  ver loss:0.0107\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0135  ver loss:0.0106\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0130  ver loss:0.0105\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0130  ver loss:0.0105\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0190  ver loss:0.0173\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0185  ver loss:0.0169\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0176  ver loss:0.0165\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0181  ver loss:0.0160\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0173  ver loss:0.0161\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0188  ver loss:0.0160\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0183  ver loss:0.0160\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0178  ver loss:0.0160\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0204  ver loss:0.0161\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0176  ver loss:0.0163\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0175  ver loss:0.0174\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0166  ver loss:0.0162\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0174  ver loss:0.0166\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0177  ver loss:0.0165\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0170  ver loss:0.0161\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0165  ver loss:0.0163\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0165  ver loss:0.0160\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0172  ver loss:0.0164\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0173  ver loss:0.0162\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0162  ver loss:0.0161\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0181  ver loss:0.0242\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0183  ver loss:0.0239\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0172  ver loss:0.0237\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0170  ver loss:0.0236\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0172  ver loss:0.0235\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0171  ver loss:0.0241\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0174  ver loss:0.0235\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0169  ver loss:0.0238\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0177  ver loss:0.0237\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0174  ver loss:0.0238\n",
      "所选模型：GRU_Encoder\n",
      "所选设备：cuda\n",
      "Epoch:10/100---------------------------\n",
      "train loss:0.0146  ver loss:0.0135\n",
      "Epoch:20/100---------------------------\n",
      "train loss:0.0151  ver loss:0.0134\n",
      "Epoch:30/100---------------------------\n",
      "train loss:0.0145  ver loss:0.0130\n",
      "Epoch:40/100---------------------------\n",
      "train loss:0.0151  ver loss:0.0127\n",
      "Epoch:50/100---------------------------\n",
      "train loss:0.0141  ver loss:0.0128\n",
      "Epoch:60/100---------------------------\n",
      "train loss:0.0149  ver loss:0.0126\n",
      "Epoch:70/100---------------------------\n",
      "train loss:0.0144  ver loss:0.0125\n",
      "Epoch:80/100---------------------------\n",
      "train loss:0.0141  ver loss:0.0126\n",
      "Epoch:90/100---------------------------\n",
      "train loss:0.0141  ver loss:0.0126\n",
      "Epoch:100/100---------------------------\n",
      "train loss:0.0152  ver loss:0.0125\n"
     ]
    }
   ],
   "source": [
    "data_dic = joblib.load('../../../../data/temp/cached_data/temp_trainset_xiaowang_1_0.joblib')\n",
    "with open(\"../../../../config/job_config/job_params.json\", \"r\") as f:\n",
    "    job_params = json.load(f)\n",
    "'''超参数'''\n",
    "train_split = 0.7\n",
    "inp_len, out_len, step_len = 16, 16, 16\n",
    "batchsize = 64\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "name_list = list(data_dic.keys())\n",
    "for name in name_list:\n",
    "    origin_data = data_dic[name]\n",
    "    train_data, test_data = origin_data.iloc[:int(0.7*len(origin_data))], origin_data.iloc[int(0.7*len(origin_data)):]\n",
    "    data_train_n, train_scale = normalization(train_data.iloc[:,1])\n",
    "    joblib.dump(train_scale, '../../../../interactive_space/{}/upload_data/scaler_{}_{}_{}_{}.joblib'.format(job_params['user_id'], name, job_params['user_id'], job_params['task_id'], job_params['job_number']))\n",
    "    data_test_n, test_scale = normalization(test_data.iloc[:,1])\n",
    "    inp_data_t, out_data_t = create_data(data_train_n, inp_len, out_len, step_len)\n",
    "    inp_data_v, out_data_v = create_data(data_test_n, inp_len, out_len, step_len)\n",
    "    # 转化为tensor\n",
    "    inp_t, out_t = torch.tensor(inp_data_t, dtype=torch.float32), torch.tensor(out_data_t, dtype=torch.float32)\n",
    "    inp_v, out_v = torch.tensor(inp_data_v, dtype=torch.float32), torch.tensor(out_data_v, dtype=torch.float32)\n",
    "    train_loader = DataLoader(TensorDataset(inp_t, out_t), shuffle=True, batch_size=batchsize)\n",
    "    test_loader = DataLoader(TensorDataset(inp_v, out_v), shuffle=False, batch_size=batchsize)\n",
    "    '''定义模型'''\n",
    "    \n",
    "    class GRU_Encoder(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim):\n",
    "            super(GRU_Encoder, self).__init__()\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "            self.fc_out = nn.Linear(hidden_dim, 1)\n",
    "        def forward(self, x):\n",
    "            out, hn = self.gru(x)\n",
    "            pre_power = self.fc_out(hn)\n",
    "            return pre_power.permute(1, 0, 2)\n",
    "        \n",
    "    GPU_switch = True\n",
    "    device = torch.device(\"cuda\" if (torch.cuda.is_available() and GPU_switch) else \"cpu\")\n",
    "    model = GRU_Encoder(1, 128).to(device)\n",
    "    print('所选模型：{}'.format(model.__class__.__name__))\n",
    "    print('所选设备：{}'.format(device))\n",
    "        \n",
    "    '''训练模型'''\n",
    "    # 开始训练\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_train_step, loss_val_step = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss_epoch = []\n",
    "        val_loss_epoch = []\n",
    "        '''1、训练过程'''\n",
    "        model.train()\n",
    "        for batch_idx, (inp_x, yy) in enumerate(train_loader):\n",
    "            inp_x, yy = inp_x.to(device), yy.to(device)\n",
    "            '''本地训练1epoch，计算梯度发送给服务器'''\n",
    "            pred = model(inp_x)\n",
    "            loss = criterion(pred, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss_epoch.append(loss.item())  # 添加一个batch的损失\n",
    "            optimizer.step()\n",
    "            \n",
    "        '''2、测试过程'''\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inp_x, yy) in enumerate(test_loader):\n",
    "                inp_x, yy = inp_x.to(device), yy.to(device)\n",
    "                pred = model(inp_x)\n",
    "                loss = criterion(pred, yy)\n",
    "                val_loss_epoch.append(loss.item())\n",
    "    \n",
    "        train_loss_epoch = np.mean(np.array(train_loss_epoch))  # 计算1个epoch的误差\n",
    "        val_loss_epoch = np.mean(np.array(val_loss_epoch))\n",
    "        loss_train_step.append(train_loss_epoch)\n",
    "        loss_val_step.append(val_loss_epoch)\n",
    "    \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch:{}/{}---------------------------'.format(epoch + 1, epochs))\n",
    "            print('train loss:{:.4f}  ver loss:{:.4f}'.format(train_loss_epoch, val_loss_epoch))\n",
    "    \n",
    "    torch.save(model.state_dict(), '../../../../interactive_space/{}/upload_data/model_para_{}_{}_{}_{}.pth'.format(job_params['user_id'], name, job_params['user_id'], job_params['task_id'], job_params['job_number']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T15:36:22.003772Z",
     "start_time": "2025-04-28T15:35:50.382903Z"
    }
   },
   "id": "dcac8bd05f779bf6",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''测试模型'''\n",
    "data_dic = joblib.load('../../../../data/temp/cached_data/temp_testset_xiaowang_1_0.joblib') # 依照数据说明遍写测试流程，输出归档结果\n",
    "\n",
    "name = 'cl'\n",
    "true_data, pre_data = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inp_x, yy) in enumerate(test_loader):\n",
    "        inp_x, yy = inp_x.to(device), yy.to(device)\n",
    "        pred = model(inp_x)\n",
    "        if yy.shape[0] != 1:\n",
    "            true_data.append(yy.cpu().numpy().squeeze())\n",
    "            pre_data.append(pred.cpu().numpy().squeeze())\n",
    "        else:\n",
    "            true_data.append(yy.cpu().numpy().reshape(1, -1))\n",
    "            pre_data.append(pred.cpu().numpy().reshape(1, -1))\n",
    "\n",
    "true = np.concatenate(true_data, axis=0)\n",
    "pre = np.concatenate(pre_data, axis=0)\n",
    "\n",
    "scaler_max, scaler_min = scaler_t.data_max_[0], scaler_t.data_min_[0]\n",
    "\n",
    "\n",
    "true_original = reverse_normalize(true, scaler_max, scaler_min)\n",
    "pre_original = reverse_normalize(pre, scaler_max, scaler_min)\n",
    "\n",
    "pickle.dump([true_original, pre_original], open('../../result/sample_result/{}_single.pkl'.format(name), 'wb'))\n",
    "pickle.dump([true, pre], open('../../result/sample_result/{}_single_n.pkl'.format(name), 'wb'))\n",
    "acc = acc_cal(true, pre)\n",
    "print('{}的预测精度为{}'.format(name, acc))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c154a3805dffe8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['../../../../interactive_space/xiaowang/upload_data/model_class_hyperparams_xiaowang_1_0.pth']"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params = {}\n",
    "for name in name_list:\n",
    "    hyper_params[name] = {'batch_size': 1, 'hidden_size': 128}\n",
    "joblib.dump(hyper_params, '../../../../interactive_space/{}/upload_data/model_class_hyperparams_{}_{}_{}.pth'.format(job_params['user_id'], job_params['user_id'], job_params['task_id'], job_params['job_number']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T01:52:42.166102Z",
     "start_time": "2025-04-29T01:52:42.152103Z"
    }
   },
   "id": "f70900c5b99fb0dd",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GRU_Encoder(\n  (gru): GRU(1, 128, batch_first=True)\n  (fc_out): Linear(in_features=128, out_features=1, bias=True)\n)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T14:50:59.899053Z",
     "start_time": "2025-04-28T14:50:59.871041Z"
    }
   },
   "id": "67e558bdc6fe0636",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a9b1e90d29a5223"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
